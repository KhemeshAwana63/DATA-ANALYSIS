{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------ CHAPTER 7 ------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HANDLING MISSING VALUES**\n",
    "- NaN - Not a number and NA - not available\n",
    "- We can filter the missing values using boolean indexing but there are specific methods made for this task\n",
    "    - dropna \n",
    "    - fillna\n",
    "    - isna\n",
    "    - notna\n",
    "- In case of dataframes the whole row or column is being dropped\n",
    "    - how=\"all\" -> drops rows/column which has all NaN\n",
    "    - thresh -> here you specify a perticular number of NaN on the basis of that it selects which row or column to delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.Series([1, np.nan, 3.5, np.nan, 7])\n",
    "data.dropna()\n",
    "data[data.notna()]\n",
    "data = pd.DataFrame([[1., 6.5, 3.], [1., np.nan, np.nan],[np.nan, np.nan, np.nan], [np.nan, 6.5, 3.]])\n",
    "data.dropna()\n",
    "data.dropna(how=\"all\" , axis=\"columns\" , thresh=2) #all of these arguments are optional\n",
    "\n",
    "data.fillna(0)\n",
    "data.fillna({1:0.5 , 2:0}) #choosing what to fill in what column using dictionary\n",
    "data.fillna(method=\"ffill\" , limit=2) #forward fill and limit is optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HANDLING DUPLICATES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"k1\": [\"one\", \"two\"] * 3 + [\"two\"], \"k2\": [1,1, 2, 3, 3, 4, 4]})\n",
    "data.duplicated() #gives a boolean object\n",
    "data.drop_duplicates(subset=[\"k1\"],keep=\"last\") #In subset we can choose multiple columns and keep tells which values to keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRANSFORMING THE DATA USING MAPPING AND FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"food\": [\"bacon\", \"pulled pork\", \"bacon\", \"pastrami\", \"corned beef\", \"bacon\", \"pastrami\", \"honey ham\", \"nova lox\"],\"ounces\": [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
    "meat_to_animal = {\"bacon\": \"pig\",\"pulled pork\": \"pig\",\"pastrami\": \"cow\",\"corned beef\": \"cow\",\"honey ham\": \"pig\",\"nova lox\": \"salmon\"}\n",
    "data[\"animal\"] = data[\"food\"].map(meat_to_animal) #this will map all the animals according to the dictionary\n",
    "\n",
    "def get_animal(x): #this is a function based approach\n",
    "    return meat_to_animal(x)\n",
    "data[\"food\"].map(get_animal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REPLACING VALUES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([1., -999., 2., -999., -1000., 3.])\n",
    "data.replace(-999, np.nan) #replacing value\n",
    "data.replace([-999 , -1000],np.nan) #replacing multiple values\n",
    "data.replace([-999 , -1000],[np.nan , 0]) #choosing different value for different element\n",
    "data.replace({-999:np.nan , -1000:0}) #by using dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RENAMING AXEX INDEXES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(12).reshape((3, 4)), index=[\"Ohio\",\"Colorado\", \"New York\"], columns=[\"one\", \"two\", \"three\", \"four\"])\n",
    "def transform(x):\n",
    "    return x[:4].upper()\n",
    "data.index = data.index.map(transform)  #it will change the index to uppercase for all characteers and this method affect the original dataframe\n",
    "\n",
    "data.rename(index=str.title , columns=str.upper) #This does not change the original dataframe\n",
    "data.rename(index={\"OHIO\":\"INDIANA\"},columns={\"three\":\"pikaboo\"}) #using dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISCRETIZATION AND BINNING**\n",
    "- It is like dividing continous data into discrete bins like age into groups\n",
    "- see the output of pd.cut() -> it is good to see that once for better understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]\n",
    "bins = [18, 25, 35, 60, 100]\n",
    "age_categories = pd.cut(ages , bin , right = False) #it categorize the ages on making intervals using bins and by default the right side of the interval is closed\n",
    "age_categories.value_counts()\n",
    "\n",
    "data = np.random.uniform(size=20)\n",
    "pd.cut(data , 4 , precision=2) #equal length bins\n",
    "\n",
    "data = np.random.standard_normal(1000) #quantile based bins(qcut)\n",
    "quartiles = pd.cut(data , 4 , precision=2)\n",
    "quartiles.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DETECTING AND FILTRING OUTLIERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.random.standard_normal((1000 , 4)))\n",
    "col = data[2]\n",
    "col[col.abs() > 3]  #values > 3 or < -3\n",
    "\n",
    "data[(data.abs() > 3).any(axis=\"columns\")] #all rows with outliers\n",
    "data[data.abs() > 3] = np.sign(data) * 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydata-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
