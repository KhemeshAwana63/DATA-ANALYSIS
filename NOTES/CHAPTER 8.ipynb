{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "615ec737",
   "metadata": {},
   "source": [
    "### Data Wrangling : Join , Combine And Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639705f3",
   "metadata": {},
   "source": [
    "Hierarchical indexing is like having a super-organized wardrobe. It’s great for:\n",
    "\n",
    "- **Reshaping data**: Using `stack()` and `unstack()` to switch between Series and DataFrame formats.\n",
    "- **Group-based operations**: Like creating pivot tables (more on this in Section 8.3).\n",
    "- **Handling complex datasets**: When data has multiple categories (e.g., sales by region and product).\n",
    "---\n",
    "- **MultiIndex is like a family tree**:  \n",
    "  Outer level (`a`, `b`, `c`) is like parents, inner level (`1`, `2`, `3`) is like kids.\n",
    "- **Unstack = spread out**:  \n",
    "  Like laying out all your rotis on a table.\n",
    "- **Stack = fold back**:  \n",
    "  Like stacking the rotis back into a pile.\n",
    "- **Partial indexing = selective munching**:  \n",
    "  Pick only the gulab jamuns you want from the sweet box!\n",
    "- **Names matter**:  \n",
    "  Giving names to index levels (`key1`, `key2`) is like labeling your dabbas so you don’t mix up dal with sabzi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452df734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.Series(np.random.uniform(size=9),index=[[\"a\", \"a\", \"a\", \"b\", \"b\", \"c\", \"c\", \"d\",\"d\"],[1, 2, 3, 1, 3, 1, 2, 2, 3]])\n",
    "data.index #MultiIndex.from_tuples([(\"a\", 1), (\"a\", 2), (\"a\", 3), (\"b\", 1), (\"b\", 3), (\"c\", 1), (\"c\", 2), (\"d\", 2), (\"d\", 3)])\n",
    "data['b'] #Indexing\n",
    "data['b':'d'] #Slicing\n",
    "data[['a','d']] #Fancy indexing\n",
    "data.loc[:,2] #Partial indexing\n",
    "data.loc['a':'b', 1:2] #Partial slicing\n",
    "data.unstack() #Unstacking - converts to DataFrame\n",
    "(data.unstack()).stack() #Stacking - converts to Series\n",
    "\n",
    "frame = pd.DataFrame(np.arange(12).reshape((4, 3)),index=[[\"a\", \"a\", \"b\", \"b\"], [1, 2, 1, 2]],columns=[[\"Ohio\", \"Ohio\", \"Colorado\"],[\"Green\", \"Red\", \"Green\"]])\n",
    "frame.index.names = ['key1','key2'] #Setting names for index levels\n",
    "frame.columns.names = ['state','color'] #Setting names for column levels\n",
    "pd.MultiIndex.from_arrays([['Ohio' ,  'Ohio' , 'Colorado'],['Green','Red','Green']],names = ['States','Color'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c4fd6b",
   "metadata": {},
   "source": [
    "**Desi Tips to Remember**\n",
    "- **swaplevel** = seat exchange: It’s just flipping two index levels, like swapping roti and naan plates. Data stays the same!\n",
    "- **sort_index** = organizing your dabba: Sort by one level or all levels to keep things neat and tidy.\n",
    "- **Sorting by level=0** = speed booster: It’s like keeping your masala box sorted so you grab spices faster.\n",
    "- **groupby with level** = summing by category: Like adding up all mithai by type (gulab jamun, jalebi) or meal time (lunch, dinner).\n",
    "- **Axis matters**: Use axis=\"columns\" for column-level operations, else it’s rows by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014c39ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.swaplevel('key1','key2') #Using lables names\n",
    "frame.swaplevel(0,1) #Using integer positions\n",
    "frame.sort_index(level= 1) #Sorting by level 1\n",
    "frame.swaplevel(0,1).sort_index(level=0) #Sorting by level 0 after swapping levels\n",
    "frame.groupby(level=0).sum() #Grouping by level 0\n",
    "frame.groupby(level = 'color',axis = 'columns').sum() #This is not allowed now you have to use transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9cbcf1",
   "metadata": {},
   "source": [
    "**Desi Breakdown – Yeh Sab Kyun Useful Hai?**\n",
    "- **set_index**: Use this when a column (or two) makes more sense as the index.\n",
    "- **set_index**= turn columns indexes to row indexes and vice versa\n",
    "- **drop=False** -> to keep the columns as columns too (not removing them)\n",
    "- **reset_index** = flattning back to dataframe(2D)\n",
    "- **Use case** = organize or flatten: set_index organizes data hierarchically; reset_index makes it simple and flat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbc1f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame({\n",
    "    \"a\": range(7),\n",
    "    \"b\": range(7, 0, -1),\n",
    "    \"c\": [\"one\", \"one\", \"one\", \"two\", \"two\", \"two\", \"two\"],\n",
    "    \"d\": [0, 1, 2, 0, 1, 2, 3]\n",
    "})\n",
    "frame2 = frame.set_index(['c', 'd'])\n",
    "frame2 = frame.set_index(['c','d'],drop = False) #Setting index without dropping the columns\n",
    "frame2.reset_index() #Resetting index -> flatten to dataframe(you can use on multiindex too)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb4370a",
   "metadata": {},
   "source": [
    "**Merge Arguments Cheat Sheet**\n",
    "- **left**: Left DataFrame.\n",
    "- **right**: Right DataFrame.\n",
    "- **how**: Join type (inner, left, right, outer).\n",
    "- **on**: Column(s) to join on (if same in both).\n",
    "- **left_on/right_on**: Columns to join on if names differ.\n",
    "- **suffixes**: Strings to add to overlapping column names (default: _x, _y).\n",
    "- **sort**: Sort result by join keys (default: False).\n",
    "- **validate**: Check if merge is one-to-one, one-to-many, etc.\n",
    "- **indicator**: Add a _merge column to show row origin (left_only, right_only, both).\n",
    "----------\n",
    "**Tips to Remember**\n",
    "- **merge** = Inner join ,Outer join,Left/Right join ,Many-to-many\n",
    "- **suffixes** = to avoid same column name conflicts\n",
    "- Indexes get dropped: merge ignores row indexes unless you use left_index or right_index (not shown here, but we can explore if you want!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc9c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    \"key\": [\"b\", \"b\", \"a\", \"c\", \"a\", \"a\", \"b\"],\n",
    "    \"data1\": pd.Series(range(7), dtype=\"Int64\")\n",
    "})\n",
    "df2 = pd.DataFrame({\n",
    "    \"key\": [\"a\", \"b\", \"d\"],\n",
    "    \"data2\": pd.Series(range(3), dtype=\"Int64\")\n",
    "})\n",
    "\n",
    "pd.merge(df1 , df2) #By defaul inner join\n",
    "pd.merge(df1 , df2 , on= 'key') #It is good to specify the key to avoid confusion\n",
    "pd.merge(df1 , df2 , how = 'outer') #Here is how we define the join type\n",
    "\n",
    "df3 = pd.DataFrame({\n",
    "    \"lkey\": [\"b\", \"b\", \"a\", \"c\", \"a\", \"a\", \"b\"],\n",
    "    \"data1\": pd.Series(range(7), dtype=\"Int64\")\n",
    "})\n",
    "df4 = pd.DataFrame({\n",
    "    \"rkey\": [\"a\", \"b\", \"d\"],\n",
    "    \"data2\": pd.Series(range(3), dtype=\"Int64\")\n",
    "})\n",
    "\n",
    "pd.merge(df3 , df4 , left_on = 'lkey' , right_on = 'rkey') #Using different keys\n",
    "# You can use multiple keys too , you can use suffixes to avoid confusion between the same named columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19291af3",
   "metadata": {},
   "source": [
    "**Key Points to Remember**\n",
    "- **Index as Merge Key**: When the merge key is in index then left_index = True and right_index = True is used\n",
    "- **Hierarchical Index**: Pass multiple columns in the list left_on , right_on\n",
    "- **join vs merge**: Join is shortcut for index based and index with column and the default is left join\n",
    "- **Preserving Index**: In join the index of left dataframe is preserved whereas in merge the key/index of both dataframe may be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ba9975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Key and index based merging\n",
    "left1 = pd.DataFrame({\n",
    "    \"key\": [\"a\", \"b\", \"a\", \"a\", \"b\", \"c\"],\n",
    "    \"value\": pd.Series(range(6), dtype=\"Int64\")\n",
    "})\n",
    "right1 = pd.DataFrame({\n",
    "    \"group_val\": [3.5, 7]\n",
    "}, index=[\"a\", \"b\"])\n",
    "result = pd.merge(left1 , right1 , left_on = 'key' , right_index = True)\n",
    "\n",
    "#When there is Heirchal index and multicolumns of key\n",
    "lefth = pd.DataFrame({\n",
    "\"key1\": [\"Ohio\", \"Ohio\", \"Ohio\", \"Nevada\", \"Nevada\"],\n",
    "\"key2\": [2000, 2001, 2002, 2001, 2002],\n",
    "\"data\": pd.Series(range(5), dtype=\"Int64\")\n",
    "})\n",
    "righth_index = pd.MultiIndex.from_arrays([\n",
    "    [\"Nevada\", \"Nevada\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\"],\n",
    "    [2001, 2000, 2000, 2000, 2001, 2002]\n",
    "])\n",
    "righth = pd.DataFrame({\n",
    "\"event1\": pd.Series([0, 2, 4, 6, 8, 10], dtype=\"Int64\", index=righth_in\n",
    " dex),\n",
    "\"event2\": pd.Series([1, 3, 5, 7, 9, 11], dtype=\"Int64\", index=righth_in\n",
    " dex)\n",
    " })\n",
    "result = pd.merge(lefth , righth , left_on = ['key1','key2'],right_index = True)\n",
    "\n",
    "#index to index merging\n",
    "left2 = pd.DataFrame([[1., 2.], [3., 4.], [5., 6.]],\n",
    "index=[\"a\", \"c\", \"e\"],\n",
    "columns=[\"Ohio\", \"Nevada\"]).astype(\"Int64\")\n",
    "right2 = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [13, 14]],\n",
    " index=[\"b\", \"c\", \"d\", \"e\"],\n",
    " columns=[\"Missouri\", \"Alabama\"]).astype(\"Int64\")\n",
    "result = pd.merge(left2 , right2 , left_index = True , right_index = True)\n",
    "\n",
    "#Now we are gonna see shortcuts using Join\n",
    "another = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [16., 17.]],\n",
    " index=[\"a\", \"c\", \"e\", \"f\"],\n",
    " columns=[\"New York\", \"Oregon\"])\n",
    "result = left2.join(right2 , how='outer')\n",
    "result = left1.join(right1 , on='key')\n",
    "resutl = left2.join([right2 , another] , how = 'outer') #Multiple dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed98caad",
   "metadata": {},
   "source": [
    "**The arguments of pd.concat**\n",
    "- **objs**\tList ya dictionary of pandas objects (Series/DataFrame) jo jodne hain. Yeh required hai.\n",
    "- **axis**\tJodne ka axis: \"index\" (rows, default) ya \"columns\".\n",
    "- **join**\t\"inner\" (common indexes) ya \"outer\" (all indexes, default).\n",
    "- **keys**\tHierarchical index banane ke liye values, jo batate hain kaunsa data kahan se aaya.\n",
    "- **levels**\tSpecific indexes for hierarchical levels agar keys pass kiye hain.\n",
    "- **names**\tHierarchical levels ke naam.\n",
    "- **verify_integrity**\tAgar True, to check karta hai ki new axis mein duplicates nahi hain. Default False.\n",
    "- **ignore_index**\tAgar True, to original indexes hata kar naye sequential index banata hai.\n",
    "-------\n",
    "For numpy we have np.concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f83da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "''''Here are the examples of numpy arrays concatenation'''\n",
    "data = np.arange(12).reshape((3,4))\n",
    "result = np.concatenate([data,data],axis = 0) #Concatenating along axis 0\n",
    "\n",
    "'''Here are the examples of pandas concat'''\n",
    "s1 = pd.Series([0,1],index = ['a','b'],dtype = 'Int64')\n",
    "s2 = pd.Series([2,3,4],index = ['c','d','e'],dtype = 'Int64')\n",
    "s3 = pd.Series([5,6],index = ['f','g'],dtype = 'Int64')\n",
    "result = pd.concat([s1,s2,s3]) #Concatenating along rows\n",
    "result = pd.concat([s1,s2,s3],axis = 'columns') #Concatenating along columns\n",
    "s4 = pd.concat([s1 , s3])\n",
    "result = pd.concat([s1 , s4],join = 'inner',axis = 'columns') #To have only the matching indexes\n",
    "result  = pd.concat([s1,s4],axis = 'columns')  #To have all the indexes\n",
    "\n",
    "#Heirchal index concate\n",
    "result  = pd.concat([s1,s1,s3],keys = ['one','two','three']) #default axis = 0 , index heirarchy\n",
    "result.unstack() #Unstacking to convert to dataframe\n",
    "df1 = pd.DataFrame(np.arange(6).reshape(3, 2), index=[\"a\", \"b\", \"c\"], columns=[\"one\", \"two\"])\n",
    "df2 = pd.DataFrame(5 + np.arange(4).reshape(2, 2), index=[\"a\", \"c\"], columns=[\"three\", \"four\"])\n",
    "result = pd.concat([df1 , df2],axis = 'columns',keys = ['level1','level2']) #Concatenating along columns with keys\n",
    "result = pd.concat([df1 , df2],axis = 'columns',keys = ['level1','level2'],names = ['upper wala','neeche wala']) #Concatenating along columns and column heirarchy with names\n",
    "\n",
    "#Dictionary method\n",
    "result = pd.concat({'level1': df1, 'level2': df2}, axis='columns') #Concatenating along columns with dictionary method\n",
    "#ignore index\n",
    "result = pd.concat([df1 , df2],axis = 'columns',ignore_index = True) #Concatenating along columns and ignoring the index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98c8feb",
   "metadata": {},
   "source": [
    "Key Points\n",
    "- **For a Series**:\n",
    "    - combine_first -> Combine_first aligns the indexes and fills the null values priority is given to the first series\n",
    "    - np.where -> also does the same work, But it does not pay attention to the indexes\n",
    "- **for a DataFrame**:\n",
    "    - combine_first column-by-column , And in the output we get the union of both the dataframes , priority is given to first dataframe\n",
    "- **Why to use?** -> When there is overlapping data in dataset and you want handle the null values smartly then this comes in handy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff27e4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series([np.nan, 2.5, 0.0, 3.5, 4.5, np.nan], index=[\"f\", \"e\", \"d\", \"c\", \"b\", \"a\"])\n",
    "b = pd.Series([0., np.nan, 2., np.nan, np.nan, 5.], index=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"])\n",
    "a.combine_first(b)  #Combining two series\n",
    "np.where(pd.isna(a), b , a) #Using numpy where to combine two series\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "\"a\": [1., np.nan, 5., np.nan],\n",
    "\"b\": [np.nan, 2., np.nan, 6.],\n",
    "\"c\": [2, 6, 10, 14]\n",
    "})\n",
    "df2 = pd.DataFrame({\n",
    "\"a\": [5., 4., np.nan, 3., 7.],\n",
    "\"b\": [np.nan, 3., 4., 6., 8.]\n",
    "})\n",
    "df1.combine_first(df2) #Combining two dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cab18e",
   "metadata": {},
   "source": [
    "**Key Points**\n",
    "- **Stack** ->\n",
    "  -  columns -> rows\n",
    "  -  Innermost columns is changed into rows by default\n",
    "  -  Missing data is filtered by defaul\n",
    "- **Unstack**\n",
    "  -  rows -> columns\n",
    "  -  Innermost row is changed into columns by default\n",
    "  -  If there is no value in sub groups then fills <NA>\n",
    "- **Level Control**:\n",
    "  -  To choose the row/columns for stacking or unstacking\n",
    "- **Invertible Operation**:\n",
    "  -  Stack and Unstack are opposite of each other..So to undo you can choose them\n",
    "  -  dropna=False Use this to keep the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b8eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(6).reshape((2, 3)),\n",
    "    index=pd.Index([\"Ohio\", \"Colorado\"], name=\"state\"),\n",
    "    columns=pd.Index([\"one\", \"two\", \"three\"], name=\"number\"))\n",
    "\n",
    "data.stack() #Stacking to convert to Hierarchal series\n",
    "data.stack().unstack() #To revert\n",
    "data.stack().unstack(level = 'state') #Unstacking by level name\n",
    "\n",
    "s1 = pd.Series([0, 1, 2, 3], index=[\"a\", \"b\", \"c\", \"d\"], dtype=\"Int64\")\n",
    "s2 = pd.Series([4, 5, 6], index=[\"c\", \"d\", \"e\"], dtype=\"Int64\")\n",
    "\n",
    "data2 = pd.concat([s1,s2],keys = ['one','two']) #Concatenating two series with keys(Creates hierarchal index)\n",
    "data2.unstack()\n",
    "data2.unstack().stack(dropna=False) #To not drop the NaN values\n",
    "\n",
    "df = pd.DataFrame({\"left\": result, \"right\": result + 5},columns=pd.Index([\"left\", \"right\"], name=\"side\"))\n",
    "df.unstack(level = 'state').stack(level = 'side')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6bb763",
   "metadata": {},
   "source": [
    "**Key Points**\n",
    "- **Long Format**:\n",
    "    - Every observations is in rows\n",
    "    - It is common in DB because adding data is easy\n",
    "- **Wide Format**:\n",
    "    - Every variable is in columns\n",
    "    - Convenient for analysis because every data is in one row\n",
    "- **Pivot Method**:\n",
    "    - pivot(index, columns, values) To change long format to wide format\n",
    "    - If values are not given then the remaining values becomes columns(hierarchical columns).\n",
    "- **Alternate Method**:\n",
    "    - set_index + unstack Does the same work\n",
    "    - set_index Creates multilevel index and unstack converts that to  columns\n",
    "    ----\n",
    "**tricks to learn**\n",
    "- Long Format: Like writing your data in a diary line by line\n",
    "- Wide Format: Its like converting that diary in a spreadsheet\n",
    "- Pivot: A button that makes long format to wide format\n",
    "-------\n",
    "**Wide to Long Format**\n",
    "- **Melt Method**:\n",
    "  - Wide to long format.\n",
    "  - id_vars: Group indicator keep columns as they are\n",
    "  - value_vars: To choose which columns to melt(if not given all are selected)\n",
    "  - **Output columns: variable (melted column names) and value (their data).\n",
    "  - **Pivot for Reverse:Opposite of melt\n",
    "  - **Flexibility: You can choose not to use any id_vars or value_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9667c1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"examples/macrodata.csv\")\n",
    "data = data.loc[:, [\"year\", \"quarter\", \"realgdp\", \"infl\", \"unemp\"]]\n",
    "\n",
    "periods = pd.PeriodIndex(year = data.pop('year'),\n",
    "                         quarter = data.pop('quarter'),\n",
    "                         name = 'date') #Creating period index from year and quarter columns\n",
    "data.index = periods.to_timestamp('D') #Converting to timestamp\n",
    "\n",
    "'''Renaming and Choosing the columns'''\n",
    "data = data.reindex(columns = ['realgdp','infl','unemp'])\n",
    "data.columns.name = 'items'\n",
    "'''Converting to long format'''\n",
    "long_data = data.stack().reset_index().rename(columns = {0:'value'})\n",
    "'''Converting to wide format from long format Using pivot'''\n",
    "pivoted = long_data.pivot(index = 'date',columns = ['items','quarter'],values = 'value')\n",
    "'''For multiple value columns'''\n",
    "long_data['values2'] = np.random.standard_normal(len(long_data))\n",
    "pivoted = long_data.pivot(index = 'date',columns = ['items','quarter'],values = ['value','values2']) \n",
    "'''Alternate method-> using unstack + set_index'''\n",
    "unstacked = pivoted.set_index(['date','items']).unstack(level = 'items')\n",
    "\n",
    "'''WIDE TO LONG FORMAT -> MELTILING'''\n",
    "df = pd.DataFrame({\"key\": [\"foo\", \"bar\", \"baz\"],\n",
    "\"A\": [1, 2, 3],\n",
    "\"B\": [4, 5, 6],\n",
    "\"C\": [7, 8, 9]})\n",
    "Melted = pd.melt(df , id_vars = 'key',value_vars=['A','B','C'])\n",
    "reshaped = Melted.pivot(index = 'key',columns= 'variable',values = 'value').reset_index()\n",
    "'''Here we could choose not to use id_vars and could choose any subset of value_vars'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydata-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
